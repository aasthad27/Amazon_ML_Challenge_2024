{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPhM5bMOzoar",
        "outputId": "ab79f4a0-8a19-4112-ea9c-99ca1c213685"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.0+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Collecting easyocr\n",
            "  Downloading easyocr-1.7.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.4.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.19.0+cu121)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from easyocr) (4.10.0.84)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.13.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from easyocr) (9.4.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.23.2)\n",
            "Collecting python-bidi (from easyocr)\n",
            "  Downloading python_bidi-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from easyocr) (6.0.2)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.0.6)\n",
            "Collecting pyclipper (from easyocr)\n",
            "  Downloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting ninja (from easyocr)\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (2024.6.1)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2.34.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2024.8.30)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (24.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->easyocr) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->easyocr) (1.3.0)\n",
            "Downloading easyocr-1.7.1-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (908 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.3/908.3 kB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_bidi-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.3/281.3 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-bidi, pyclipper, ninja, easyocr\n",
            "Successfully installed easyocr-1.7.1 ninja-1.11.1.1 pyclipper-1.3.0.post5 python-bidi-0.6.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision torchaudio\n",
        "!pip install easyocr\n",
        "!pip install transformers\n",
        "!pip install opencv-python-headless"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import requests\n",
        "from requests.adapters import HTTPAdapter\n",
        "from urllib3.util.retry import Retry\n",
        "import time\n",
        "import easyocr\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Initialize EasyOCR reader for English language\n",
        "reader = easyocr.Reader(['en'], gpu=True)\n",
        "\n",
        "# Load the Data (ensure paths are correct)\n",
        "test_csv_file_path = r'/content/test.csv'\n",
        "output_file_path = r'/content/result_out_65000_80000.csv'\n",
        "\n",
        "# Load test data\n",
        "test_df = pd.read_csv(test_csv_file_path)\n",
        "\n",
        "# Filter the DataFrame for rows between index 39,000 and 60,000\n",
        "filtered_df = test_df[(test_df['index'] >= 85001) & (test_df['index'] <= 105000)]\n",
        "\n",
        "# Create output CSV file if it doesn't exist\n",
        "if not os.path.exists(output_file_path):\n",
        "    with open(output_file_path, 'w') as f:\n",
        "        f.write(\"prediction index,prediction\\n\")\n",
        "\n",
        "# Function to configure session with retries and larger connection pool\n",
        "def create_session():\n",
        "    session = requests.Session()\n",
        "    # Increase pool size and set retries\n",
        "    adapter = HTTPAdapter(pool_connections=100, pool_maxsize=100)  # Increased pool size\n",
        "    retries = Retry(total=3, backoff_factor=1, status_forcelist=[502, 503, 504])\n",
        "    session.mount('http://', adapter)\n",
        "    session.mount('https://', adapter)\n",
        "    session.adapters['http://'].max_retries = retries\n",
        "    session.adapters['https://'].max_retries = retries\n",
        "    return session\n",
        "\n",
        "# Function to download image using requests session\n",
        "def download_image(image_link, save_folder, session, retries=3, delay=1):\n",
        "    filename = Path(image_link).name\n",
        "    image_save_path = os.path.join(save_folder, filename)\n",
        "\n",
        "    if os.path.exists(image_save_path):\n",
        "        return image_save_path\n",
        "\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            response = session.get(image_link, stream=True, timeout=10)\n",
        "            if response.status_code == 200:\n",
        "                with open(image_save_path, 'wb') as f:\n",
        "                    for chunk in response.iter_content(1024):\n",
        "                        f.write(chunk)\n",
        "                return image_save_path\n",
        "        except Exception as e:\n",
        "            time.sleep(delay)\n",
        "\n",
        "    return None\n",
        "\n",
        "# Optimized parallel image download using session-based requests with an increased connection pool\n",
        "def download_images_concurrently(image_links, save_folder):\n",
        "    with ThreadPoolExecutor(max_workers=20) as executor:  # Increase workers for more parallelism\n",
        "        with create_session() as session:\n",
        "            futures = {executor.submit(download_image, link, save_folder, session): link for link in image_links}\n",
        "            for future in as_completed(futures):\n",
        "                link = futures[future]\n",
        "                try:\n",
        "                    future.result()\n",
        "                except Exception as exc:\n",
        "                    print(f\"Failed to download image {link}: {exc}\")\n",
        "\n",
        "# Function to extract text from an image\n",
        "def extract_text_from_image(image_path):\n",
        "    results = reader.readtext(image_path)\n",
        "    extracted_text = ' '.join([result[1] for result in results])\n",
        "    return extracted_text\n",
        "\n",
        "# Function to categorize extracted text using regex patterns\n",
        "entity_patterns = {\n",
        "    \"item_weight\": r'(\\d+(\\.\\d+)?\\s?(g|kg|mg|lb))',\n",
        "    \"item_volume\": r'(\\d+(\\.\\d+)?\\s?(ml|l|fl oz|gal))',\n",
        "    \"height\": r'(\\d+(\\.\\d+)?\\s?(cm|mm|in|ft))',\n",
        "    \"width\": r'(\\d+(\\.\\d+)?\\s?(cm|mm|in|ft))',\n",
        "    \"depth\": r'(\\d+(\\.\\d+)?\\s?(cm|mm|in|ft))',\n",
        "    \"voltage\": r'(\\d+(\\.\\d+)?\\s?(V|kV|mV))',\n",
        "    \"wattage\": r'(\\d+(\\.\\d+)?\\s?(W|kW))',\n",
        "    \"maximum_weight_recommendation\": r'(\\d+(\\.\\d+)?\\s?(g|kg|lb))'\n",
        "}\n",
        "\n",
        "def categorize_text_by_entity(extracted_text, entity_name):\n",
        "    pattern = entity_patterns.get(entity_name.lower())\n",
        "    if pattern:\n",
        "        matches = re.findall(pattern, extracted_text, re.IGNORECASE)\n",
        "        return matches[0][0] if matches else None\n",
        "    return None\n",
        "\n",
        "# Process the dataset and save results in chunks\n",
        "def process_and_save_results(df, save_folder, output_file):\n",
        "    for idx, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing Images\"):\n",
        "        image_url = row['image_link']\n",
        "        entity_name = row['entity_name']\n",
        "        index = row['index']\n",
        "\n",
        "        image_filename = Path(image_url).name\n",
        "        image_path = os.path.join(save_folder, image_filename)\n",
        "\n",
        "        # Download image if not already present\n",
        "        if not os.path.exists(image_path):\n",
        "            image_path = download_image(image_url, save_folder, requests.Session())\n",
        "\n",
        "        if not image_path:\n",
        "            continue  # Skip if the image could not be downloaded\n",
        "\n",
        "        # Extract text from the image\n",
        "        extracted_text = extract_text_from_image(image_path)\n",
        "\n",
        "        # Categorize text based on entity name\n",
        "        predicted_value = categorize_text_by_entity(extracted_text, entity_name)\n",
        "\n",
        "        # Store the result\n",
        "        with open(output_file, 'a') as f:\n",
        "            f.write(f\"{index},{predicted_value}\\n\")\n",
        "\n",
        "# Define save folder for images\n",
        "save_folder = '/content/images'\n",
        "os.makedirs(save_folder, exist_ok=True)\n",
        "\n",
        "# Download images concurrently before processing\n",
        "image_links = filtered_df['image_link'].unique()\n",
        "download_images_concurrently(image_links, save_folder)\n",
        "\n",
        "# Start processing the filtered dataset and storing results\n",
        "process_and_save_results(filtered_df, save_folder, output_file_path)\n",
        "\n",
        "print(\"Processing complete. Results saved in result_out.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LP-2Pdnz1FV",
        "outputId": "cfd98a2d-4602-43d6-ec91-e0f6f8a17fdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
            "/usr/local/lib/python3.10/dist-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
            "Processing Images: 100%|██████████| 19993/19993 [3:28:38<00:00,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complete. Results saved in result_out.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}